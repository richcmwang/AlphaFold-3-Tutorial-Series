{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "363b0e9e-da30-45d0-a3cc-2fc8c3218727",
      "metadata": {
        "id": "363b0e9e-da30-45d0-a3cc-2fc8c3218727"
      },
      "source": [
        "# AlphaFold 3 Walkthrough\n",
        "\n",
        "## Introduction\n",
        "AlphaFold 3 (AF3) is a multimodal structure prediction model that extends AlphaFold 2 to handle not only proteins, but also ligands, DNA/RNA, antibodies, ions, and more. It predicts all-atom 3D structures from diverse input data, including sequences, structural templates, and small molecules.\n",
        "\n",
        "This walkthrough is intended as a high-level guide for students, developers, and researchers seeking to understand AF3’s architectural flow and practical usage. It focuses on the structure and logic of the model, rather than low-level implementation details, and is well-suited for tutorials, onboarding, or early-stage exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3346e12-0121-4988-94a3-5427d9284872",
      "metadata": {
        "id": "f3346e12-0121-4988-94a3-5427d9284872"
      },
      "source": [
        "![panel_a](https://github.com/richcmwang/AlphaFold-3-Tutorial-Series/blob/main/images/architecture.png?raw=1)\n",
        "\n",
        "<span style=\"font-size:90%;\">\n",
        "<b>Figure 1. End-to-end architecture of AlphaFold 3.</b>\n",
        "This diagram summarizes the full prediction pipeline, from input processing and embedding to structure refinement and confidence estimation. Input features include sequences, optional MSAs, template structures, and ligand conformers. Representations are passed through a series of embedding modules and the 48-block Pairformer. Recycling and a training-time diffusion module enable progressive refinement. Final atomic coordinates and confidence scores are output after structure prediction.\n",
        "Adapted from Figure 1d of the AlphaFold 3 paper (Evans et al., 2024).\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6810d990-2752-4cbd-9722-75e23e49bc24",
      "metadata": {
        "id": "6810d990-2752-4cbd-9722-75e23e49bc24"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Please run the cell below to download the tutorial files and set the correct working directory. This ensures that all images and utility files are accessible during the walkthrough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d99dcb-c526-4eb6-b69a-faef5bfeccf0",
      "metadata": {
        "id": "a6d99dcb-c526-4eb6-b69a-faef5bfeccf0"
      },
      "outputs": [],
      "source": [
        "# Clone the tutorial repository\n",
        "!git clone https://github.com/richcmwang/AlphaFold-3-Tutorial-Series.git\n",
        "\n",
        "# Change working directory to the 'tutorials' folder\n",
        "import os\n",
        "os.chdir('AlphaFold-3-Tutorial-Series/tutorials')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe2fa3b-9276-4034-8a7d-310b32ce2830",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "efe2fa3b-9276-4034-8a7d-310b32ce2830"
      },
      "source": [
        "## 1. Input and Featurization Construction\n",
        "\n",
        "AlphaFold 3 begins structure prediction by converting molecular inputs into internal features that encode shape, chemistry, and spatial relationships. These are constructed from data such as protein sequences, ligand CCD codes or SMILES, and optional structural templates like .cif files.\n",
        "\n",
        "If templates are provided, for example, a protein backbone or a CCD-defined small molecule, they are used to compute geometric features including pairwise distances, bond angles, and torsions. These are expressed relative to local coordinate frames, ensuring that featurization depends only on internal geometry, not on absolute 3D placement.\n",
        "\n",
        "Unlike AlphaFold 2, AlphaFold 3 treats multiple sequence alignments (MSAs) as optional input and is trained to make accurate predictions even from a single protein sequence.\n",
        "\n",
        "The model also computes atom-level features such as atom types, valency, and bond connectivity. These features form the input representation used by AlphaFold’s neural network architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4513337-ce5c-4205-b71d-4318270ee67f",
      "metadata": {
        "id": "e4513337-ce5c-4205-b71d-4318270ee67f"
      },
      "source": [
        "## 2. Model Representations\n",
        "\n",
        "Internally, AlphaFold 3 represents molecules using two interlinked feature types: single and pairwise representations. The single representation is a vector for each token, representing either a residue or an atom, and capturing its local chemical identity and context. These are stored in a tensor of shape n × c, where n is the number of tokens and c is the number of channels.\n",
        "\n",
        "The pairwise representation captures the spatial relationship between every pair of tokens (residues or atoms) using a tensor of shape n × n × c. For each token pair, the model encodes not just the distance between them, but also how they are oriented with respect to one another and any torsion-like angles that describe their relative rotation. All of these geometric features are computed in local coordinate frames, which ensures that the model's reasoning is invariant to how the system is positioned or rotated in space\n",
        "\n",
        "These two representations evolve throughout the network via the Pairformer module, which alternates between updating single-token features based on pairwise context and refining pairwise features using updated token states. This joint refinement enables the model to reason over both local identity and global structure in a consistent geometric framework."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db172405-6744-4ed5-9f16-26321ae640d3",
      "metadata": {
        "id": "db172405-6744-4ed5-9f16-26321ae640d3"
      },
      "source": [
        "## 3. Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bd0991e-652f-4d71-8e98-bd5975edf5d8",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "1bd0991e-652f-4d71-8e98-bd5975edf5d8"
      },
      "source": [
        "### 3.1 Overview of AlphaFold3 Architecture\n",
        "\n",
        "AlphaFold 3 uses a transformer-based architecture designed to reason jointly over proteins, RNAs, ligands, and their complexes. Rather than building in strict SE(3)-equivariance as seen in some geometric deep learning models, AlphaFold 3 relies on the strength of large-scale, diverse training data to learn spatial reasoning directly. This reflects a broader trend in modern architectures: replacing inductive biases with general-purpose models when data is sufficient.\n",
        "\n",
        "Although AlphaFold 3 is not formally SE(3)-equivariant, it achieves rotation and translation invariance by basing its reasoning entirely on local, relative geometry. Because the model operates on internal features like distances, directions, and angles defined in local frames, its predictions are unaffected by how the input is globally oriented or positioned.\n",
        "\n",
        "AlphaFold 3 encodes modality-specific behavior through learned input embeddings. The same model architecture is used across all supported modalities, including proteins, ligands, RNAs, ions, and small molecules. Rather than relying on separate model pipelines, this unified design enables the model to flexibly handle a wide range of molecular systems—such as protein–ligand complexes or protein–RNA assemblies—without retraining or architectural changes.\n",
        "\n",
        "Unlike AlphaFold 2, which used local residue frames to transform torsion angle predictions into global 3D atom positions, AlphaFold 3 predicts global atomic coordinates directly. This architectural shift reflects both design and training changes, including how spatial features are integrated through attention mechanisms and how structure prediction is supervised. The model learns to place atoms directly into a shared 3D frame, without relying on intermediate local-to-global transformations.\n",
        "\n",
        "Additionally, AlphaFold 3’s attention mechanisms naturally integrate information across different molecule types. Inter-molecular attention allows the model to learn from interactions between protein residues, ligand atoms, and other molecular components without relying on predefined binding pockets or rigid docking constraints. Ligand atoms, including their flexible torsions, are treated as first-class tokens and participate in the same representation updates as proteins and RNAs. This design enables AlphaFold 3 to handle complex systems like protein–ligand or protein–RNA assemblies with a unified model.\n",
        "\n",
        "Key architectural components include the Pairformer module, which refines single-token and pairwise representations through geometry-aware attention, and the diffusion module, which iteratively denoises predicted structures for accurate 3D atomic coordinates. These components are described in detail in the following sections.\n",
        "\n",
        "When provided, MSA features are processed by a dedicated module at the start of the model to extract co-evolutionary patterns, similar to AlphaFold 2, but are no longer essential for accurate prediction, as AlphaFold 3 is trained to operate robustly even in their absence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2233fdd4-b285-47d9-be82-c85a9226ce0f",
      "metadata": {
        "id": "2233fdd4-b285-47d9-be82-c85a9226ce0f"
      },
      "source": [
        "### 3.2 Pairformer Module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8196e6a8-1258-42aa-8046-1b5acccedc09",
      "metadata": {
        "id": "8196e6a8-1258-42aa-8046-1b5acccedc09"
      },
      "source": [
        "![panel_a](https://github.com/richcmwang/AlphaFold-3-Tutorial-Series/blob/main/images/pairformer.png?raw=1)\n",
        "<span style=\"font-size:90%;\">\n",
        "<b>Figure 2. Pairformer Module for Updating Pairwise and Single-Token Representations.</b> Pairwise geometric context and token-level embeddings are integrated through 48 blocks of triangle update, triangle self-attention, transition layers, and single attention with pair bias. Adapted from the AlphaFold 3 paper.\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61010dd4-4914-44a2-b84c-fac615c1ae76",
      "metadata": {
        "id": "61010dd4-4914-44a2-b84c-fac615c1ae76"
      },
      "source": [
        "The Pairformer module is the core of AlphaFold 3’s architecture, adapted from the Evoformer in AlphaFold 2. It consists of 48 sequential layers that iteratively refine the single-token and pairwise representations.\n",
        "\n",
        "The triangle update and self-attention blocks of the module form triangles by connecting any pair (i, j) with a third node k that links to both i and j and aggregates information from all such k nodes to refine the pairwise representation P[i, j].\n",
        "\n",
        "The following diagrams (Jumper et al,. 2021) illustrate how these blocks aggregate information from neighboring triangles. Outgoing and incoming edges capture directional relationships, with outgoing edges representing (i to k) and (j to k) and incoming edges representing (k to i) and (k to j), while starting and ending node self-attention mechanisms integrate geometric context from different parts of the molecular graph. Together, these modules help the model understand complex 3D arrangements, which is critical for accurate structure prediction.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/richcmwang/AlphaFold-3-Tutorial-Series/blob/main/images/triangle.png?raw=1\" width=\"700\">\n",
        "<div align=\"center\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transition layers include lightweight feed-forward networks that refine the representations, stabilize learning, and enable deeper architectures.\n",
        "\n",
        "Single attention with pair bias module updates the single-token embeddings by incorporating geometric context from the pairwise features. In AlphaFold 3, the pair representation biases the attention logits of the single attention module. This design allows the model to integrate pairwise geometric information into single-token embeddings while maintaining architectural simplicity.\n",
        "\n",
        "Together, these operations enable the Pairformer to build a geometry-aware representation of the molecular system that is passed downstream to the diffusion module for iterative denoising and final structure prediction."
      ],
      "metadata": {
        "id": "KAyE_vPDndXC"
      },
      "id": "KAyE_vPDndXC"
    },
    {
      "cell_type": "markdown",
      "id": "b362327e-a8d2-4880-9e41-9ee9d80637b8",
      "metadata": {
        "id": "b362327e-a8d2-4880-9e41-9ee9d80637b8"
      },
      "source": [
        "### 3.3 Diffusion Module\n",
        "\n",
        "#### Overview\n",
        "\n",
        "AlphaFold 3 uses a diffusion module to perturb input geometries during training, teaching the model to recover accurate atomic structures through iterative denoising. This conditional generative training procedure allows the model to learn protein structure at multiple length scales: at low noise levels, it captures local stereochemistry, while at high noise levels, it captures the overall global arrangement of the system. At inference time, AlphaFold 3 samples random noise conditioned on the input features (such as the protein sequence and ligand graph) and denoises it recurrently to generate a final structure. This approach enables the model to produce a distribution of answers, each with sharply defined local geometry, even in regions of global uncertainty. By using this conditional generative process, AlphaFold 3 avoids the need for torsion-based parametrizations and violation losses while effectively handling complex multimolecular systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211a4ad4-c2d7-43ca-83b8-9903c6f61a2e",
      "metadata": {
        "id": "211a4ad4-c2d7-43ca-83b8-9903c6f61a2e"
      },
      "source": [
        "#### Input Preparation\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/richcmwang/AlphaFold-3-Tutorial-Series/blob/main/images/attention.png?raw=1\" width=\"500\">\n",
        "</div>\n",
        "<span style=\"font-size:90%;\">\n",
        "<b>Figure 3. Input Processing for the Diffusion Module.</b> This figure summarizes input preparation steps, including per token (single-token and pairwise) and per-atom representations, as well as random rotations and translations before feeding them into the diffusion module. The per-token conditioning module receives processed outputs from earlier modules (Pairformer, template, and MSA), ensuring that the diffusion module (shown as the bottom attention blocks) receives refined features for iterative denoising and structure prediction.\n",
        "</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27630d8c-4393-443a-aec7-3e32a87391e2",
      "metadata": {
        "id": "27630d8c-4393-443a-aec7-3e32a87391e2"
      },
      "source": [
        "The input features are prepared with 3 conditional modules before entering the diffusion module. The per-token conditioning module integrates raw input features (green bars, e.g. sequence, atom type) with geometric context from pairwise features (blue squares) and outputs refined single-token embeddings (red bars). These pairwise and single representations have already been processed by the Pairformer stack and, optionally, the template and MSA modules.\n",
        "\n",
        "The per-atom conditioning module uses atom-level features, including chemical identity, bonding, and local geometric context to create enriched atom embeddings robust to rotation and translation. Rather than relying solely on raw 3D coordinates, the per-atom representation module integrates the refined single-token embeddings (from the per-token representation) with relative geometric features such as distances, angles, and local frames to build a robust, SE(3)-aware atom embedding. This design ensures that each atom representation captures both local chemical context and spatial relationships within the molecule.\n",
        "\n",
        "Additionally, random rotation and translation are applied to the input structures before diffusion noise is added, ensuring the model learns to denoise consistently regardless of orientation.\n",
        "\n",
        "The three attention blocks at the bottom of the diagram collectively form the diffusion module, where iterative denoising refines atomic coordinates. Readers can refer back to the main AlphaFold 3 architecture diagram (Figure 1) for the complete view of how these inputs connect to the diffusion module."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa520ca-e71c-45c4-8cff-f2c19a24ef63",
      "metadata": {
        "id": "0fa520ca-e71c-45c4-8cff-f2c19a24ef63"
      },
      "source": [
        "#### Training and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f71586-b989-41a8-b7c5-7cea8acee3a0",
      "metadata": {
        "id": "a5f71586-b989-41a8-b7c5-7cea8acee3a0"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://github.com/richcmwang/AlphaFold-3-Tutorial-Series/blob/main/images/training.png?raw=1\" width=\"800\">\n",
        "</div>\n",
        "\n",
        "<span style=\"font-size:90%;\">\n",
        "<b>Figure 4. Diffusion module input and output in AlphaFold 3.</b> This figure shows how the model’s activations, the outputs of the Pairformer (network trunk), feed into the diffusion module. Single-token embeddings (red), pairwise features (blue), and original input features (green) are processed by the diffusion module, where iterative denoising refines atomic coordinates. A STOP sign indicates where gradient flow is halted during training. Adapted from Figure 2 in the AlphaFold 3 paper (Evans et al., 2024).\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ebdd72-e8fa-4e51-b52f-7dfa217c622b",
      "metadata": {
        "id": "f1ebdd72-e8fa-4e51-b52f-7dfa217c622b"
      },
      "source": [
        "AlphaFold 3 trains its diffusion module using both a training diffusion block and an inference diffusion block. During training, the model perturbs input structures with noise and teaches the diffusion module to denoise them by comparing the denoised outputs to the ground truth structure.\n",
        "\n",
        "The inference diffusion block performs a mini-rollout of iterative denoising steps (e.g. 20 iterations) during training to supervise the model’s intermediate predictions and guide learning from early stages of the denoising process. Although a STOP sign in the architecture prevents gradients from flowing back through the inference diffusion block itself, the weights of the inference and training diffusion modules are shared. As a result, the loss computed from the inference rollout still contributes to updating the model’s parameters.\n",
        "\n",
        "The “Permute ground truth” step acts as a data augmentation technique to enforce permutation invariance during training.\n",
        "\n",
        "The combination of the training and inference diffusion blocks, the shared weights, and the STOP gradients ensures that the model learns to produce accurate structures consistently throughout the denoising process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c98a1d62-740a-4646-8b28-4b118d992585",
      "metadata": {
        "id": "c98a1d62-740a-4646-8b28-4b118d992585"
      },
      "source": [
        "## 4. Ligand Modeling\n",
        "\n",
        "In AlphaFold 3, ligands are represented as molecular graphs with atom- and bond-level features, derived from the Chemical Component Dictionary (CCD) and processed using RDKit. These include atomic identity, bond order, and torsion flexibility. RDKit provides an initial 3D conformer as input, but AlphaFold 3 predicts the ligand’s final pose in the context of the binding site, including both its spatial placement and the torsion angles of flexible bonds. This allows the model to refine the ligand’s internal conformation to match the local environment. Rather than relying on predefined rules or scoring functions, AlphaFold 3 learns spatial interaction patterns such as the avoidance of atomic clashes (steric fit), hydrogen bonding, and shape complementarity directly from training data. AlphaFold 3 predicts torsion angles for each rotatable bond in the ligand, enabling the reconstruction of a chemically plausible 3D conformation.\n",
        "\n",
        "## 5. Pose Prediction\n",
        "\n",
        "AlphaFold 3 outputs all-atom 3D coordinates for every molecule in the input system, including proteins, ligands, nucleic acids, ions, and water molecules. These coordinates form a unified structural prediction, suitable for downstream analysis or visualization.\n",
        "\n",
        "For ligands, the model predicts detailed binding poses, resolving not just rigid-body placement but also flexible torsion angles around rotatable bonds. This enables AlphaFold 3 to capture the internal conformation of small molecules as they adapt to their binding environment.\n",
        "\n",
        "For proteins, the model resolves both backbone geometry and side-chain conformations at atomic resolution, recovering detailed structural features such as rotamer states and hydrogen bonding patterns.\n",
        "\n",
        "All coordinates are provided in a consistent global reference frame that is arbitrary with respect to the input orientation. Because AlphaFold 3 uses only internal geometry for featurization, the predicted structure can be translated or rotated without loss of fidelity. The global coordinate system used in AlphaFold 3’s output does not carry biological meaning on its own. However, it is applied consistently across all molecules in the system, so relative positions and interactions such as ligand binding, side-chain packing, or ion coordination can still be interpreted accurately.\n",
        "\n",
        "Because AlphaFold 3 relies on relative geometry, it is invariant to input orientation. Unlike models such as DiffDock that require globally aligned inputs, AlphaFold 3 accepts unaligned structures and produces consistent results. While it reasons over internal coordinates, its outputs are absolute: all-atom 3D coordinates supervised on ground-truth structures.\n",
        "\n",
        "\n",
        "## 6. Recycling\n",
        "AlphaFold 3 performs iterative recycling, a process in which the model refines its predictions by feeding the predicted structure from one iteration back into the network. The sequence, ligand information, and any template or MSA features remain fixed, but the updated coordinates from the predicted structure are used to recompute the single-token and pairwise representations. This allows the system to progressively improve both geometric accuracy and representational quality, especially in complex systems involving flexible ligands, multi-molecular interfaces, or disordered regions.\n",
        "\n",
        "## 7. Confidence Estimation\n",
        "The model outputs several forms of structural confidence and quality metrics. One key output is the Predicted Aligned Error (PAE), which estimates the expected positional error between pairs of residues or atoms after optimal alignment. This matrix is particularly useful for evaluating the reliability of domain orientations and inter-molecular contacts.\n",
        "\n",
        "Another important metric is the Predicted Local Distance Difference Test (pLDDT), which provides a per-atom or per-residue score indicating how confidently the model believes it has positioned each part of the structure. Higher pLDDT scores (typically ranging from 0 to 100) correspond to greater local reliability, with values above 70 often indicating regions that are well-resolved and trustworthy. This metric is particularly useful for assessing the quality of flexible regions within a protein or complex such as loops and side chains as well as binding pockets and small molecules that can adopt multiple conformations depending on their environment. For these challenging regions, pLDDT highlights areas where the model’s predictions might be less certain, helping researchers identify parts of the structure that may require additional validation or experimental support.\n",
        "\n",
        "Together, these confidence metrics help users evaluate the reliability of the prediction, focus on high-confidence regions, and guide follow-up modeling or experimental efforts."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "alphafold3",
      "language": "python",
      "name": "alphafold3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}